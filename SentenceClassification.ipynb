{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sentence Classification using CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "import random\n",
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "fname = 'finegrained.txt'\n",
    "\n",
    "def read_data(file):\n",
    "    \n",
    "    with open(file, 'r') as f:\n",
    "    \n",
    "        sent = ['pos', 'neg', 'neu']\n",
    "\n",
    "        sentiment = []\n",
    "        review = []\n",
    "\n",
    "        for sen in f:\n",
    "            if len(sen.strip()) != 0 :\n",
    "\n",
    "                row = sen.lower().strip().split()\n",
    "\n",
    "                if row[0] in sent:\n",
    "\n",
    "                    sentiment.append(row[0])\n",
    "                    review.append(row[1:])\n",
    "    \n",
    "    return sentiment, review\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max length of sentence: 155\n",
      "\n",
      "sentiment: ['neg', 'neg', 'neg', 'neg', 'neg']\n",
      "\n",
      "review:\n",
      " [['the', 'book', 'is', 'disproportionally', 'focused', 'on', 'single', 'and', 'multilayer', 'feedforward', 'networks.'], ['and', 'though', 'the', 'book', 'puts', 'great', 'emphasis', 'on', 'mathematics', 'and', 'even', 'includes', 'a', 'big', 'section', 'on', 'important', 'mathematical', 'background', 'knowledge,', 'it', 'contains', 'to', 'many', 'errors', 'in', 'the', 'mathematical', 'formulas,', 'so', 'they', 'are', 'of', 'little', 'use.'], ['the', 'author', \"hasn't\", 'even', 'taken', 'the', 'trouble', 'to', 'put', 'up', 'an', 'errata', 'list.'], ['finally,', 'for', 'the', 'beginner', 'there', 'are', 'not', 'enough', 'conceptual', 'clues', 'on', 'what', 'is', 'actually', 'going', 'on', 'and', 'it', 'is', 'hard', 'to', 'form', 'any', 'mental', 'model', 'of', 'the', 'underlying', 'processes.'], ['there', 'are', 'better', 'books.']]\n"
     ]
    }
   ],
   "source": [
    "sent, rev = read_data(fname)\n",
    "\n",
    "print('max length of sentence:', len(max(rev, key = len)))\n",
    "print('\\nsentiment:',sent[:5])\n",
    "print('\\nreview:\\n', rev[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Padding and shortening the sentences with certain threshold and making the reviews of equal length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 75\n",
    "\n",
    "def normalizing_reviews(reviews):\n",
    "    norm_review = []\n",
    "    \n",
    "    for review in reviews:\n",
    "        if len(review) < threshold:\n",
    "            norm_review.append(review + ['PAD']*(threshold - len(review)))\n",
    "        \n",
    "        elif len(review) > threshold:\n",
    "            norm_review.append(review[:threshold])\n",
    "            \n",
    "        else:\n",
    "            norm_review.append(review)\n",
    "            \n",
    "    return norm_review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "review length: 75\n",
      "\n",
      "reviews:\n",
      " [['the', 'book', 'is', 'disproportionally', 'focused', 'on', 'single', 'and', 'multilayer', 'feedforward', 'networks.', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD'], ['and', 'though', 'the', 'book', 'puts', 'great', 'emphasis', 'on', 'mathematics', 'and', 'even', 'includes', 'a', 'big', 'section', 'on', 'important', 'mathematical', 'background', 'knowledge,', 'it', 'contains', 'to', 'many', 'errors', 'in', 'the', 'mathematical', 'formulas,', 'so', 'they', 'are', 'of', 'little', 'use.', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD'], ['the', 'author', \"hasn't\", 'even', 'taken', 'the', 'trouble', 'to', 'put', 'up', 'an', 'errata', 'list.', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD'], ['finally,', 'for', 'the', 'beginner', 'there', 'are', 'not', 'enough', 'conceptual', 'clues', 'on', 'what', 'is', 'actually', 'going', 'on', 'and', 'it', 'is', 'hard', 'to', 'form', 'any', 'mental', 'model', 'of', 'the', 'underlying', 'processes.', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD'], ['there', 'are', 'better', 'books.', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD']]\n"
     ]
    }
   ],
   "source": [
    "norm_rev = normalizing_reviews(rev)\n",
    "\n",
    "print('review length:', len(norm_rev[0]))\n",
    "print('\\nreviews:\\n', norm_rev[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating Dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = 10000\n",
    "\n",
    "def create_dict(normalized_reviews):\n",
    "    global vocab_size\n",
    "    words = []\n",
    "    \n",
    "    for review in normalized_reviews:\n",
    "        words.extend(review)\n",
    "    print('length of words:', len(words))\n",
    "    print('words in the vocabulary: %d'%len(collections.Counter(words).most_common()))\n",
    "\n",
    "    count = [['UNK', -1]]\n",
    "    count.extend(collections.Counter(words).most_common(vocab_size - 1))\n",
    "\n",
    "    dictionary = dict()\n",
    "    for word, _ in count:\n",
    "        dictionary[word] = len(dictionary)\n",
    "\n",
    "    rev_dictionary = dict(zip(dictionary.values(), dictionary.keys()))\n",
    "\n",
    "    return dictionary, rev_dictionary, count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of words: 188625\n",
      "words in the vocabulary: 11162\n",
      "dictionary ['1994', 'stickers,', 'herself', 'who', '\"unfold\"', 'zil...or', 'performance.', 'foreign', 'diminish', 'overall,']\n",
      "reverse dictionary [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
      "most common words: [['UNK', -1], ('PAD', 140018), ('the', 2729), ('and', 1311), ('a', 1181)]\n",
      "len of dictionary: 10000\n"
     ]
    }
   ],
   "source": [
    "dictionary, rev_dictionary, count = create_dict(norm_rev)\n",
    "\n",
    "print('dictionary', list(dictionary)[:10])\n",
    "print('reverse dictionary', list(rev_dictionary)[:10])\n",
    "print('most common words:', count[0:5])\n",
    "print('len of dictionary:', len(dictionary))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Converting str to int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def str_to_int(normalized_reviews, dictionary):\n",
    "    \n",
    "    review_int = []\n",
    "    \n",
    "    for review in normalized_reviews:\n",
    "        norm_rev_int = []\n",
    "        \n",
    "        for word in review:\n",
    "            if word in dictionary:\n",
    "                norm_rev_int.append(dictionary[word])\n",
    "            else:\n",
    "                norm_rev_int.append(dictionary['UNK'])\n",
    "        \n",
    "        review_int.append(norm_rev_int)\n",
    "    \n",
    "    return review_int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "review int[0]:\n",
      " [2, 74, 7, 8755, 3065, 17, 318, 3, 3936, 5036, 2354, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "\n",
      "review int[1]:\n",
      " [3, 255, 2, 74, 793, 66, 1499, 17, 9868, 3, 57, 870, 4, 244, 1002, 17, 1000, 3039, 1022, 9145, 10, 1551, 5, 91, 1690, 11, 2, 3039, 9041, 29, 30, 18, 6, 92, 808, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n"
     ]
    }
   ],
   "source": [
    "rev_int = str_to_int(norm_rev, dictionary)\n",
    "\n",
    "print('review int[0]:\\n', rev_int[0])\n",
    "print('\\nreview int[1]:\\n', rev_int[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train and Test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_indices = random.sample(list(range(len(rev_int))), 500)\n",
    "\n",
    "train_rev = [rev_int[idx] for idx in range(len(rev_int)) if idx not in test_indices]\n",
    "test_rev = [rev_int[idx] for idx in test_indices]\n",
    "             \n",
    "train_sent = [sent[idx] for idx in range(len(sent)) if idx not in test_indices]\n",
    "test_sent = [sent[idx] for idx in test_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train reviews: [2, 74, 7, 8755, 3065, 17, 318, 3, 3936, 5036, 2354, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "\n",
      "test reviews: [9, 379, 22, 369, 16, 22, 4, 274, 2812, 37, 2, 354, 4790, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "\n",
      "train sentiments: ['neg', 'neg', 'neg', 'neg', 'neg', 'neu', 'neg', 'neg', 'neg', 'neg', 'neg', 'neg', 'neg', 'pos', 'neg', 'neg', 'neg', 'neg', 'neg', 'neg', 'neg', 'neg', 'neg', 'neg', 'pos']\n",
      "\n",
      "test sentiments: ['neu', 'neg', 'pos', 'neg', 'neg', 'neg', 'neg', 'neg', 'neg', 'pos', 'neu', 'neg', 'pos', 'neg', 'pos', 'neg', 'neu', 'pos', 'neg', 'neg', 'pos', 'neg', 'pos', 'neg', 'neg']\n"
     ]
    }
   ],
   "source": [
    "print('train reviews:', train_rev[0])\n",
    "print('\\ntest reviews:', test_rev[0])\n",
    "print('\\ntrain sentiments:', train_sent[:25])\n",
    "print('\\ntest sentiments:', test_sent[0:25])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate batches od data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = len(dictionary)\n",
    "num_labels = 3\n",
    "sent_length = threshold\n",
    "sentiments = ['pos', 'neg', 'neu']\n",
    "\n",
    "def generate_batch(train_review, train_sentiment, batch_size, batch_no):\n",
    "    global vocab_size, num_labels, sent_length, sentiments\n",
    "    \n",
    "    inputs = np.zeros((batch_size, sent_length, vocab_size))\n",
    "    labels = np.zeros((batch_size, num_labels))\n",
    "    \n",
    "    train_review = train_review[batch_no*batch_size : batch_no*batch_size + batch_size]\n",
    "    train_sentiment = train_sentiment[batch_no*batch_size : batch_no*batch_size + batch_size]\n",
    "    \n",
    "    for review_idx, review in enumerate(train_review):\n",
    "        for idx, word in enumerate(review):\n",
    "            \n",
    "            inputs[review_idx, idx, word] = 1\n",
    "    \n",
    "    for idx, sent in enumerate(train_sentiment):\n",
    "        labels[idx, sentiments.index(sent)] = 1\n",
    "        \n",
    "        \n",
    "    return inputs, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train labels for a batch: [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 0 1 1 1]\n",
      "train labels:\n",
      " [[0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [1. 0. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [1. 0. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]]\n",
      "test labels for a batch: [1 0 2 0 1 2 0 1 1 1 1 1 1 0 0 0 2 0 1 0 2 2 0 1 0 1 1 1 1 1 1 1]\n",
      "test labels:\n",
      " [[0. 1. 0.]\n",
      " [1. 0. 0.]\n",
      " [0. 0. 1.]\n",
      " [1. 0. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 0. 1.]\n",
      " [1. 0. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [0. 0. 1.]\n",
      " [1. 0. 0.]\n",
      " [0. 1. 0.]\n",
      " [1. 0. 0.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [1. 0. 0.]\n",
      " [0. 1. 0.]\n",
      " [1. 0. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]]\n"
     ]
    }
   ],
   "source": [
    "inputs, labels = generate_batch(train_rev, train_sent, 32, 1)\n",
    "test_inputs, test_labels = generate_batch(test_rev, test_sent, 32, 1)\n",
    "\n",
    "print('train labels for a batch:', np.argmax(labels, axis = 1))\n",
    "print('train labels:\\n', labels)\n",
    "\n",
    "print('test labels for a batch:', np.argmax(test_labels, axis = 1))\n",
    "print('test labels:\\n', test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sentence classification using CNN\n",
    "#### There will be 3 parallel layers in 1 convulation layer and a fully connected layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameters and inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 50\n",
    "learning_rate = 0.01\n",
    "batch_size = 32\n",
    "# filter sizes in a single convolutional layer \n",
    "filter_sizes = [3, 5, 7]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_inputs = tf.placeholder(tf.float32, shape = [batch_size, sent_length, vocab_size], name = 'train_inputs')\n",
    "train_labels = tf.placeholder(tf.float32, shape = [batch_size, num_labels])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### weights and biases for each parallel layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "w1 = tf.Variable(tf.truncated_normal([filter_sizes[0], vocab_size, 1], stddev = 0.02, dtype = tf.float32), name = 'weights_1')\n",
    "b1 = tf.Variable(tf.random_uniform([1], 0, 0.01, dtype = tf.float32), name = 'bias_1')\n",
    "\n",
    "w2 = tf.Variable(tf.truncated_normal([filter_sizes[1], vocab_size, 1], stddev = 0.02, dtype = tf.float32), name = 'weights_2')\n",
    "b2 = tf.Variable(tf.random_uniform([1], 0, 0.01, dtype = tf.float32), name = 'bias_2')\n",
    "\n",
    "w3 = tf.Variable(tf.truncated_normal([filter_sizes[2], vocab_size, 1], stddev = 0.02, dtype = tf.float32), name = 'weights_3')\n",
    "b3 = tf.Variable(tf.random_uniform([1], 0, 0.01, dtype = tf.float32), name = 'bias_2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### weights and biases for fully connected layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "w_fc1 = tf.Variable(tf.truncated_normal([len(filter_sizes), num_labels], stddev = 0.5, dtype = tf.float32), name = 'weights_fc1')\n",
    "b_fc1 = tf.Variable(tf.random_uniform([num_labels], 0, 0.01, dtype = tf.float32), name = 'bias_fc1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Layer computations or Inference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### convolution part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "h_conv1 = tf.nn.relu(tf.nn.conv1d(train_inputs, w1, stride = 1, padding = 'SAME') + b1)\n",
    "h_conv2 = tf.nn.relu(tf.nn.conv1d(train_inputs, w2, stride = 1, padding = 'SAME') + b2)\n",
    "h_conv3 = tf.nn.relu(tf.nn.conv1d(train_inputs, w3, stride = 1, padding = 'SAME') + b3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### maxpooling part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "h_pool1 = tf.reduce_max(h_conv1,axis=1)\n",
    "h_pool2 = tf.reduce_max(h_conv2,axis=1)\n",
    "h_pool3 = tf.reduce_max(h_conv3,axis=1)\n",
    "\n",
    "# concatenating\n",
    "h_pool = tf.concat([h_pool1, h_pool2, h_pool3], axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "logits = tf.matmul(h_pool, w_fc1) + b_fc1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits = logits, labels = train_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.train.AdamOptimizer(learning_rate = 0.001).minimize(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = tf.argmax(tf.nn.softmax(logits), axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run model to classify sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/monu/anaconda3/envs/tensorflow/lib/python3.5/site-packages/tensorflow/python/client/session.py:1711: UserWarning: An interactive session is already active. This can cause out-of-memory errors in some cases. You must explicitly call `InteractiveSession.close()` to release resources held by the other session(s).\n",
      "  warnings.warn('An interactive session is already active. This can '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss at Epoch 0: 1.08\n",
      "Test accuracy at Epoch 0: 53.542\n",
      "Train Loss at Epoch 1: 1.03\n",
      "Test accuracy at Epoch 1: 53.542\n",
      "Train Loss at Epoch 2: 0.99\n",
      "Test accuracy at Epoch 2: 53.542\n",
      "Train Loss at Epoch 3: 0.95\n",
      "Test accuracy at Epoch 3: 53.542\n",
      "Train Loss at Epoch 4: 0.91\n",
      "Test accuracy at Epoch 4: 53.542\n",
      "Train Loss at Epoch 5: 0.89\n",
      "Test accuracy at Epoch 5: 53.125\n",
      "Train Loss at Epoch 6: 0.86\n",
      "Test accuracy at Epoch 6: 53.542\n",
      "Train Loss at Epoch 7: 0.84\n",
      "Test accuracy at Epoch 7: 53.542\n",
      "Train Loss at Epoch 8: 0.82\n",
      "Test accuracy at Epoch 8: 53.750\n",
      "Train Loss at Epoch 9: 0.80\n",
      "Test accuracy at Epoch 9: 55.000\n",
      "Train Loss at Epoch 10: 0.78\n",
      "Test accuracy at Epoch 10: 56.250\n",
      "Train Loss at Epoch 11: 0.76\n",
      "Test accuracy at Epoch 11: 55.833\n",
      "Train Loss at Epoch 12: 0.73\n",
      "Test accuracy at Epoch 12: 55.208\n",
      "Train Loss at Epoch 13: 0.71\n",
      "Test accuracy at Epoch 13: 55.000\n",
      "Train Loss at Epoch 14: 0.69\n",
      "Test accuracy at Epoch 14: 55.000\n",
      "Train Loss at Epoch 15: 0.67\n",
      "Test accuracy at Epoch 15: 55.000\n",
      "Train Loss at Epoch 16: 0.65\n",
      "Test accuracy at Epoch 16: 54.792\n",
      "Train Loss at Epoch 17: 0.63\n",
      "Test accuracy at Epoch 17: 55.417\n",
      "Train Loss at Epoch 18: 0.61\n",
      "Test accuracy at Epoch 18: 55.000\n",
      "Train Loss at Epoch 19: 0.59\n",
      "Test accuracy at Epoch 19: 54.583\n",
      "Train Loss at Epoch 20: 0.57\n",
      "Test accuracy at Epoch 20: 54.792\n",
      "Train Loss at Epoch 21: 0.55\n",
      "Test accuracy at Epoch 21: 54.375\n",
      "Train Loss at Epoch 22: 0.54\n",
      "Test accuracy at Epoch 22: 54.792\n",
      "Train Loss at Epoch 23: 0.52\n",
      "Test accuracy at Epoch 23: 55.417\n",
      "Train Loss at Epoch 24: 0.51\n",
      "Test accuracy at Epoch 24: 54.792\n",
      "Train Loss at Epoch 25: 0.49\n",
      "Test accuracy at Epoch 25: 54.375\n",
      "Train Loss at Epoch 26: 0.48\n",
      "Test accuracy at Epoch 26: 53.958\n",
      "Train Loss at Epoch 27: 0.47\n",
      "Test accuracy at Epoch 27: 53.333\n",
      "Train Loss at Epoch 28: 0.46\n",
      "Test accuracy at Epoch 28: 53.333\n",
      "Train Loss at Epoch 29: 0.44\n",
      "Test accuracy at Epoch 29: 53.333\n",
      "Train Loss at Epoch 30: 0.43\n",
      "Test accuracy at Epoch 30: 52.500\n",
      "Train Loss at Epoch 31: 0.42\n",
      "Test accuracy at Epoch 31: 52.083\n",
      "Train Loss at Epoch 32: 0.41\n",
      "Test accuracy at Epoch 32: 51.667\n",
      "Train Loss at Epoch 33: 0.40\n",
      "Test accuracy at Epoch 33: 52.292\n",
      "Train Loss at Epoch 34: 0.39\n",
      "Test accuracy at Epoch 34: 52.500\n",
      "Train Loss at Epoch 35: 0.38\n",
      "Test accuracy at Epoch 35: 51.875\n",
      "Train Loss at Epoch 36: 0.38\n",
      "Test accuracy at Epoch 36: 51.458\n",
      "Train Loss at Epoch 37: 0.37\n",
      "Test accuracy at Epoch 37: 51.458\n",
      "Train Loss at Epoch 38: 0.36\n",
      "Test accuracy at Epoch 38: 51.458\n",
      "Train Loss at Epoch 39: 0.35\n",
      "Test accuracy at Epoch 39: 51.250\n",
      "Train Loss at Epoch 40: 0.34\n",
      "Test accuracy at Epoch 40: 51.458\n",
      "Train Loss at Epoch 41: 0.33\n",
      "Test accuracy at Epoch 41: 52.083\n",
      "Train Loss at Epoch 42: 0.32\n",
      "Test accuracy at Epoch 42: 51.250\n",
      "Train Loss at Epoch 43: 0.31\n",
      "Test accuracy at Epoch 43: 51.667\n",
      "Train Loss at Epoch 44: 0.31\n",
      "Test accuracy at Epoch 44: 50.833\n",
      "Train Loss at Epoch 45: 0.30\n",
      "Test accuracy at Epoch 45: 51.458\n",
      "Train Loss at Epoch 46: 0.29\n",
      "Test accuracy at Epoch 46: 51.250\n",
      "Train Loss at Epoch 47: 0.28\n",
      "Test accuracy at Epoch 47: 51.667\n",
      "Train Loss at Epoch 48: 0.27\n",
      "Test accuracy at Epoch 48: 51.875\n",
      "Train Loss at Epoch 49: 0.26\n",
      "Test accuracy at Epoch 49: 51.875\n"
     ]
    }
   ],
   "source": [
    "session = tf.InteractiveSession()\n",
    "\n",
    "tf.global_variables_initializer().run()\n",
    "\n",
    "def accuracy(labels,preds):\n",
    "    return np.sum(np.argmax(labels,axis=1)==preds)/labels.shape[0]\n",
    "\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    avg_loss = []\n",
    "    \n",
    "    for step in range((len(train_rev) - 1) // batch_size):\n",
    "        batch_inputs, batch_labels = generate_batch(train_rev, train_sent, batch_size, step)\n",
    "        \n",
    "        feed_dict = {train_inputs: batch_inputs, train_labels: batch_labels}\n",
    "        \n",
    "        l, _ = session.run([loss, optimizer], feed_dict = feed_dict)\n",
    "        \n",
    "        avg_loss.append(l)\n",
    "        \n",
    "    print('Train Loss at Epoch %d: %.2f'%(epoch,np.mean(avg_loss)))\n",
    "    \n",
    "    test_accuracy = []\n",
    "    \n",
    "    for step in range((len(test_rev) - 1) // batch_size):\n",
    "        batch_test_inputs, batch_test_labels = generate_batch(test_rev, test_sent, batch_size, step)\n",
    "\n",
    "        feed_dict = {train_inputs: batch_test_inputs, train_labels: batch_test_labels}\n",
    "\n",
    "        preds = session.run([predictions], feed_dict = feed_dict)\n",
    "\n",
    "        test_accuracy.append(accuracy(batch_test_labels, preds))\n",
    "        \n",
    "    print('Test accuracy at Epoch %d: %.3f'%(epoch,np.mean(test_accuracy)*100.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
